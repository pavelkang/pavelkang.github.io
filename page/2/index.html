<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Kai Kang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="a place of sharing tech, food">
<meta property="og:type" content="website">
<meta property="og:title" content="Kai Kang">
<meta property="og:url" content="https://pavelkang.github.io/page/2/">
<meta property="og:site_name" content="Kai Kang">
<meta property="og:description" content="a place of sharing tech, food">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kai Kang">
<meta name="twitter:description" content="a place of sharing tech, food">

  
    <link rel="alternative" href="/atom.xml" title="Kai Kang" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">

  
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-53656983-2', 'auto');
ga('send', 'pageview');

</script>


</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Kai Kang</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Carpe diem</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/resume">Resume</a>
        
          <a class="main-nav-link" href="http://www.kaikang.me">Visit My Home Page</a>
        
      </nav>
      <nav id="sub-nav">
        <a id="nav-github-link" class="nav-icon" href="https://github.com/pavelkang"></a>
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="submit" value="&#xF002;" class="search-form-submit"><input type="hidden" name="q" value="site:https://pavelkang.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post--15251-Uncountability-and-Uncomputability" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/31/-15251-Uncountability-and-Uncomputability/" class="article-date">
  <time datetime="2015-01-31T22:55:35.000Z" itemprop="datePublished">Jan 31 2015</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/31/-15251-Uncountability-and-Uncomputability/">[15251 Uncountability and Uncomputability]</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <ul>
<li>Injective: $a \neq a’ \rightarrow f(a) \neq f(a’)$</li>
<li>Surjective: $\forall b\in B, \exists a\in A, f(a) = b$</li>
<li>Bijective</li>
</ul>
<p>$\mathbb{N} = \mathbb{Z}$<br><em>Countable</em> = finite or countably infinite<br><strong>Cantor’s Theorem</strong><br>For any non-empty set $A$, $|A|\lt |P(A)|$. This can be proven by <em>diagonalization</em>. $S = a\in A: a\notin f(a)$ $S$ is defined by diagonalization so that $S$ cannot equal any $f(a)$.<br><strong>Continuum Hypothesis (Hilbert’s 1st Problem)</strong><br>There is no set $S$ such that $|\mathbb{N}|\lt |S|\lt |P(\mathbb{N})|$</p>
<p><em>String encoding</em>: Computational problems can be <em>serialized</em> into a string</p>
<h3 id="Computational_Complexity">Computational Complexity</h3>
<ul>
<li>Every multitape TM has an equivalent single tape TM.</li>
<li>Running time depends on the particular model you choose</li>
<li>Running time is defined as $T_A(n) = max{# \text{steps A takes on I}}$ (max input instance)</li>
<li><em>intrinsic complexity</em> is defined by $min$ (min algorithm).</li>
<li>Entscheidungsproblem: Decide whether a given statement is valid with a given set of axioms</li>
<li>To compute summations:<ul>
<li>Rough bounding</li>
<li>Exact computation</li>
<li>Induction</li>
<li>Telescoping series ($\frac{1}{i(i+1)}$)</li>
<li>Comparison with an integral</li>
</ul>
</li>
<li><strong>Master Method</strong><br>For $T(n) \le a\dot T(\frac{n}{b}) + O(n^d)$,<ul>
<li>$a = b^d$, $O(n^dlog n)$</li>
<li>$a &lt; b^d$, $O(n^d)$</li>
<li>$a &gt; b^d$, $O(n^{log_ba})$</li>
</ul>
</li>
</ul>
<p>Countable:</p>
<ul>
<li>countable cartesian product of countable sets<ul>
<li>Prime factorization</li>
</ul>
</li>
<li>Countable union of countable sets</li>
<li>Set of Finite Subsets of Countable Set<ul>
<li>Induction</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2015/01/31/-15251-Uncountability-and-Uncomputability/" data-id="aotud5mb20zvj18y" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2015/01/31/-15251-Uncountability-and-Uncomputability/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/251/">251</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/math/">math</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post--15251-Formalization-of-Proof-Finite-Automata" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/22/-15251-Formalization-of-Proof-Finite-Automata/" class="article-date">
  <time datetime="2015-01-22T23:53:05.000Z" itemprop="datePublished">Jan 22 2015</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/22/-15251-Formalization-of-Proof-Finite-Automata/">[15251] Formalization of Proof, Finite Automata</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <h1 id="Formalization_of_Proof">Formalization of Proof</h1>
<p><em>First Order Logic</em> = Prop. Logic + {$\forall$, $\exists$, $=$, “constants”, “relations”, “functions”}<br>Variables are now <em>objects</em>.<br><em>Vocabulary</em> is a collection of constant-names, function-names, relation-names.<br><em>Interpretation</em></p>
<ul>
<li>Specifies the <em>universe</em></li>
<li>Maps constant-name to object</li>
<li>Maps relation-name to actual relation</li>
<li>Maps function-name to actual function<br><em>Satisfiability/Tautology</em>: Similar to that in first order logic.</li>
</ul>
<h1 id="Finite_Automata">Finite Automata</h1>
<p><em>Alphabet</em>: A nonempty finite set $\Sigma$ of symbols, $\Sigma = {0, 1}$ usually.<br><em>String</em>: A finite sequence of 0 or more symbols.</p>
<ul>
<li>The length-0 string is $\epsilon$</li>
<li>$\Sigma^n$ means all strings with length n.</li>
<li>$\Sigma^{*}$ means all strings over $\Sigma$</li>
</ul>
<p><em>Language</em>: A collection of strings. A subset of $\Sigma^{*}$.</p>
<p>Thus, we can think of a decision problem as a function:<br>$f: \Sigma^{*} \rightarrow {NO, YES}$<br>Decision problem is finding a language L such that f(element in L) is true</p>
<p><strong>DFA</strong>: $L(M) = x\in \Sigma^{*}: M \text{accepts } x$.</p>
<p>A <strong>deterministic finite automaton</strong> is a 5-tuple:</p>
<ul>
<li>$Q$ is a nonempty finite set of states</li>
<li>$\Sigma$ is an alphabet</li>
<li>$\delta: Q * \Sigma \rightarrow Q$ is the transition function</li>
<li>$q_0\in Q$ is the start state</li>
<li>$F\subset Q$ is the set of accepting states</li>
</ul>
<p><strong>Accept</strong><br>Let $w = w_1w_2w_3…w_n$<br>We say that <strong>M accepts string w</strong> if there exists states $r_0r_1…r_n\in Q$ such that</p>
<ul>
<li>$r_0 = q_0$</li>
<li>$\delta(r_{t-1}, w_t) = r_t$ for all $t$</li>
<li>$r_n\in F$.<br>Otherwise, we say $M$ <strong>rejects</strong> $w$.<br>The sequence $r_1r_2…r_n$ is called the <em>computation trace</em>.</li>
</ul>
<p><strong>Regular Languages</strong><br>A language is regular if there is a DFA that decides it</p>
<p><strong>Proving a language is not regular</strong></p>
<ol>
<li>Assume for contradiction there is a DFA M which decides language L</li>
<li>Argue there are two strings x, y which reach the same state in M.</li>
<li>Show there is a string z such that $xz\in L$ and $yz\notin L$.<br>Example: $a^nb^n$</li>
</ol>
<ul>
<li>$L_1\cup L_2$ is regular if $L_1$ and $L_2$ are.(Union Theorem)</li>
<li>$L_1\dot L_2$ (concatenation)</li>
<li>$L^{*}$ is regular if $L$ is.</li>
</ul>
<p><strong>More on Regular Languages</strong></p>
<ol>
<li>The empty language is regular</li>
<li>The singleton of empty string is regular</li>
<li>The singleton of each character in the alpahbet is regular</li>
<li>Union</li>
<li>Concatenation</li>
<li>Kleene star</li>
<li>In fact, all set operations can be performed<br>(On how to prove a language is regular)[<a href="http://cseweb.ucsd.edu/~clbailey/ClosureProofTemplate.htm" target="_blank" rel="external">http://cseweb.ucsd.edu/~clbailey/ClosureProofTemplate.htm</a>]<br>(On how to prove regular languages are closed under reverse)[<a href="http://web.cecs.pdx.edu/~hook/cs581sp11/reverse.pdf" target="_blank" rel="external">http://web.cecs.pdx.edu/~hook/cs581sp11/reverse.pdf</a>]<br><em>Pumping Lemma</em> Not really understand</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2015/01/22/-15251-Formalization-of-Proof-Finite-Automata/" data-id="rd7irjl9y0damy3o" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2015/01/22/-15251-Formalization-of-Proof-Finite-Automata/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/251/">251</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/math/">math</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Machine-Learning-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/21/Machine-Learning-Notes/" class="article-date">
  <time datetime="2015-01-21T15:41:09.000Z" itemprop="datePublished">Jan 21 2015</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/21/Machine-Learning-Notes/">Machine Learning Notes</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <h3 id="Undirected_Graphical_Models">Undirected Graphical Models</h3>
<ul>
<li>Inference, parameter learning (MLE), Structure learning (Prior over graphs, Regularization)</li>
<li>Markov Blanket</li>
<li>DGM but not UGM: rain, sprinkle -&gt; wet</li>
<li>Inference: Generally intractable (approx. algorithms: MCMC)</li>
<li>Parameter Learning:<ul>
<li>Complete Data -&gt; Iterative Methods, max ent: doable but non-trivial</li>
<li>Incomplete Data -&gt; E-M</li>
<li>Cannot generate data for undirected graphs (very hard)</li>
<li>How to generate data from Undirected Graphical Model<ul>
<li>Random Walk</li>
</ul>
</li>
<li>Supervised learning: Data are labeled</li>
<li>Query: Nearest neighbor (works for classification and regression)</li>
</ul>
</li>
</ul>
<h3 id="Bayesian_Belief_Network">Bayesian Belief Network</h3>
<ul>
<li>every node, conditioned on all immediate parents, is independent of all non-descendants</li>
<li>$O(2^{|\text{Parents}|})$: Factorization.</li>
<li>c -&gt; r -&gt; w. c is not independent of w. However, conditioned on KNOWing r, w is independent of c.</li>
<li>Parameter Learning in DGM</li>
<li>If there are complete data, then just need to worry about smoothing</li>
<li>incomplete -&gt; EM algorithm. MLE from incomplete data</li>
<li>Structure learning</li>
</ul>
<ol>
<li>initialize u1, u2, … to some guess (centers of clusters of data points)</li>
<li>calculate “probabilistic assignment” of each $x_i$:</li>
<li>Re-estimate</li>
</ol>
<p>1st-order Markov Assumption</p>
<p>L-Z compression(1/3)<br>本来有一段信息basketball，compress。这需要compression algorithm to be adaptive<br>做20次添加到basketball的末尾，比对compress的结果。最后compression最短的那个添加的东西和basketball最有关</p>
<p>传送信息的时候，有小的DT但是有exceptions, 我们要找到rule + 处理exception的平衡（最短的）<br>MDL: Minimum Description Length</p>
<h3 id="Naive_Bayes_Algorithm">Naive Bayes Algorithm</h3>
<ul>
<li>Conjunction of attributes to a finite set of output</li>
</ul>
<h1 id="Lecture_19_Naive_Bayes">Lecture 19 Naive Bayes</h1>
<ul>
<li>Conditional independent vs. truly independent<ul>
<li>z = x XOR y: if z=0, then x tells me y, y tells me x, but x, y independent</li>
</ul>
</li>
<li>Naive Bayes: overly confident<ul>
<li>因为对于不是iid的data，假设了他们都independent，都乘起来就会overly confident</li>
</ul>
</li>
</ul>
<h1 id="Lecture_17">Lecture 17</h1>
<ul>
<li>Find $h_map$:<ul>
<li>如果不好直接算最大值就取log。和对likelihood取log，算导数一样</li>
</ul>
</li>
<li>Example: Gaussian<ul>
<li>Given data $x_1, x_2, …$, assume $\sigma^2 = 1$, estimate u</li>
<li>hard bias: choice of gaussian; soft: max-likelihood method<br>-</li>
</ul>
</li>
</ul>
<h1 id="Lecture_16">Lecture 16</h1>
<ul>
<li>Q1: How good is a hypothesis?<ul>
<li>True error: $Err_D(h)$ (confidence interval of true error)</li>
</ul>
</li>
<li>Q2: Is my hypothesis better than yours:<ul>
<li>$d = Err_Dh_B - Err_Dh_A$</li>
<li>$\hat{d} = Err<em>{SA}….Err</em>{SB}$: unbiased estimation (notes有公式，很像confidence interval. SA SB are two samples better be similar. Pair Test. 比如一个班做两套不同的卷子是不合理的)</li>
</ul>
</li>
<li>Q3: Is my learning algorithm better than yours:<ul>
<li>$h=L_A(s)$ (s is the training sample)</li>
<li>We compare $Err_D(L_A(s))$, $Err_D(L_B(s))$. (s是蓝色的(observed), 所以这两个数都是observed，所以对于不同的training sample, 结果可能不一样。所以变成左右两边取expetation.)</li>
<li>对于一些s当做training，用test sample测error，可以找到d hat。如果sample有限就每次拿出来一点当training另外的当testing</li>
</ul>
</li>
</ul>
<h3 id="Bayesian_Learning">Bayesian Learning</h3>
<ul>
<li>Probabilistic soft bias. $\forall h\in H, p(h)$ captures initial belief.</li>
<li>Consistency -&gt; Match $P(D|h)$: likelihood</li>
<li>Bayes Game<ul>
<li>Start with $H = (h_1, h_2, …, h_n)$. PRIOR(INITIAL): $p(h)$.</li>
<li>Data D</li>
<li>Likelihood $P(D|h)$</li>
<li>Bayes formula(MUST)<ul>
<li>$P(h, D) = P(h) <em> P(D|h) = P(D) </em> P(h|D)$</li>
<li>$P(h)$ captures the belief BEFORE seeing the data, PRIOR</li>
<li>$P(h|D)$ captures … AFTER, POSTERIOR</li>
<li>$P(h|D) = \frac{P(D|h) * P(h)}{P(D)}$</li>
<li>If we have some prior belief and likelihood, after we see some data, the posterior is something we should believe. Bayesian learning updates your belief about life.</li>
<li>$h_{map}$是maximize posterior $p(h|D)$的h</li>
<li>如果$p(h)=\frac{1}{|H|}$, 那就相当于maximize$p(D|h)$, likelihood. 也叫 max likelihood hypothesis</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Lecture_1">Lecture 1</h1>
<h3 id="Jan_14_Wed">Jan 14 Wed</h3>
<hr>
<p><strong>Machine Learning</strong>: program that gets better at some tasks(functions) with experiences(data, examples)<br>Formalizing a task as a function learning task (f: board pos -&gt; next move)<br><em>Human Annotation</em>: human assigning scores</p>
<ul>
<li>f: INPUT -&gt; {choice1, choice2, …} : <em>classification</em></li>
<li>f: INPUT -&gt; Real : <em>Regression</em></li>
<li>f: INPUT -&gt; {0, 1} probability: <em>Logistic Regression</em></li>
<li>f: INPUT -&gt; P(INPUT) <em>Probability Density Estimation</em><br>Binary Classification = Concept Learning = Learning a subset of $X$.</li>
</ul>
<h1 id="Lecture_2">Lecture 2</h1>
<h3 id="Wed_Jan_21_10:48:53_EST_2015">Wed Jan 21 10:48:53 EST 2015</h3>
<hr>
<ul>
<li><em>Input space</em>: A set of features</li>
<li><em>Target Concept</em>: The concept or function to be learned, denoted by $c$, a boolean-<br>valued function defined over the instances $X$; that is, $c$ : $X \rightarrow {0, 1}$</li>
<li><em>Training Examples</em>: $D$</li>
<li><em>Hypothesis</em> Conjunctions of literals. Eg $&lt;?, Cold, High, ?, ?&gt;$. We are looking for $h$ in the set of all possible hypothesis $H$ such that $\forall x, h(x) = c(x)$</li>
<li>$|X| \ll |H| \ll |C| = 2^x$, $|C|$ is the set of all possible functions (concept space)</li>
<li>X is input space, H is hypothesis space (each item + 1), C is concept space ($2^{|X|}$)</li>
</ul>
<h1 id="Lecture_3">Lecture 3</h1>
<p>$D={(x_1, c(x_1)), …}$ data<br>Each concept c_i is a bit vector.</p>
<p><strong>Hypothesis consistency</strong> $Consistent(h, D) = \forall <x, c(x)="">\in D, h(x) = c(x)$<br><strong>Version space</strong> $VS_{H,D} = {h\in H| Consistent(h, D)}$</x,></p>
<h3 id="Find-S_algorithm">Find-S algorithm</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">hypo = &lt;null, null, ...&gt; <span class="comment"># says NO to everything</span></div><div class="line"><span class="comment"># D is the data {(x1, c(x1)), (x2, c(x2)), ...}</span></div><div class="line"><span class="comment"># looking for target concept c in C</span></div><div class="line"><span class="keyword">for</span> positive_example <span class="keyword">in</span> D:</div><div class="line">    <span class="keyword">for</span> attribute_constraint <span class="keyword">in</span> hypo:</div><div class="line">        <span class="keyword">if</span> pos_example satisfied by attr_constraint: <span class="keyword">pass</span></div><div class="line">        <span class="keyword">else</span>: hypo := next more general constraint satisfied by attr_constraint</div><div class="line"><span class="keyword">return</span> hypo</div></pre></td></tr></table></figure>

<h3 id="Problems_with_Find-S">Problems with Find-S</h3>
<ul>
<li>Fails when training data inconsistent</li>
<li>Picks a maximally specific $h$</li>
</ul>
<h3 id="List-Then-Eliminate">List-Then-Eliminate</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hypos = a list containing every hypothesis</div><div class="line"><span class="keyword">for</span> &lt;x, c(x)&gt; <span class="keyword">in</span> D:</div><div class="line">    remove h <span class="keyword">in</span> hypos <span class="keyword">if</span> h(x) != c(x)</div><div class="line"><span class="keyword">return</span> hypos</div></pre></td></tr></table></figure>

<h1 id="Lecture_4_Informaiton_theory">Lecture 4 Informaiton theory</h1>
<p><strong>Bias</strong></p>
<ul>
<li>Hard bias: eg. “Language bias” (conjunctions)</li>
<li>Soft bias: “ranking”, preference bias (prefer hypothesis that tends to say NO)</li>
</ul>
<p>Information = Reduction in Uncertainty<br>Suprisal = information received when observing an outcome = $I(\text{sunny}) = log_2 \frac{1}{prob(\text{sunny})} \in [0, \infty)$<br>Information is <em>additive</em>:</p>
<h1 id="Lecture_5">Lecture 5</h1>
<p>Suprise(Information learned) = $log<em>2\frac{1}{p(e)}$, where $p(e)$ is <em>subjective</em>, int <strong>BITS</strong>.<br><strong>Cross Entropy</strong> $\Sigma p_i I(s_i)$.<br><strong>Fundamental Inequality</strong><br><strong>Distance</strong> $D</em>{KL}(p||q) = E_p[log\frac{p(x)}{q(x)}]\ge 0$<br>A special case would be $p = q$, when we fully know the “truth”. $0\lte CH(p, p) \lte log k$, where $log k$ is fully uniform. <em>20 questions game</em>.<br>Ask questions which answers you think are equally likely to be $0$ and $1$, so that you can learn the most information.</p>
<p>$H(Letter) = log{27} = 4.75 BITS$.</p>
<h1 id="Lecture_6">Lecture 6</h1>
<p>Entropy is a tight lower bound of efficiency of emitting events.<br><em>Regular Variable</em>: holds a <em>single</em> value.<br><em>Random Variable</em>: distribution<br>Joint Entropy, Conditional Entropy, Average Conditional Entropy.<br>Average Conditional Entropy, $H(T/M)$.<br>$H(T) - H(M/T)$, how much $M$ is telling us on average about $T$.<br>$H(T) - H(M/T) = H(M) - H(M/T)$<br>$I(X; Y; Z) = I(X,Y) - I(X,Y|Z)$<br>$I(X, Y) = H(X) - H(X|Y)$<br>$I(y, {x_1, x_2, …}) = I(y, x_1) + (y; x_2|x_1) + I(y, x_3|x_1, x_2) + …$</p>
<h1 id="Lecture_7">Lecture 7</h1>
<h3 id="Decision_Tree">Decision Tree</h3>
<p>Same attribute will not appear twice in a single path</p>
<h1 id="Lecture_8">Lecture 8</h1>
<p>Draw a decision tree from $f(A, B, C, D, E) = (A\wedge B)\vee (C\wedge \not D\wedge E)$<br>Decision trees can represent any functions.</p>
<h1 id="Lecture_9">Lecture 9</h1>
<p>Law of total variance: $VAR(y) = VAR(E[y|x]) + E[VAR(y|x)]$<br>First: how far apart the centers are<br>Second: WITHIN-CLUSTER VARIANCE</p>
<h1 id="Lecture_11">Lecture 11</h1>
<h3 id="Linear_Regression">Linear Regression</h3>
<p>To a multi-linear regression: $\beta<em>{OLS} = (X^TX)^{-1}(X^TY)$<br>Hard bias: …<br>Soft bias: square of residue<br>_Sparse Estimation</em>: p &gt;&gt; n. $\beta$ is non-identifiable</p>
<ul>
<li>L2 Norm(sum of squared beta): “Ridge Regression”</li>
<li>L1 Norm(sum of abs beta): “Lasso Regression”</li>
<li>L0 Norm(number of non-zero beta)<br><em>Regularization</em>: minimize $argmin(Error(data, param) + Complexity(Param))$<br>In this example: square of residues + norm of Beta</li>
</ul>
<h1 id="Lecture_12">Lecture 12</h1>
<h3 id="Neural_Networks">Neural Networks</h3>
<p>Works really well with <em>complex real-world sensor-data</em><br>Since human neurons switch slowly compared to computers, but is able to do complicated computations quickly. It is conjectured that humans do parallel computation.<br>Learning corresponds to assigning weights to edges in an acyclic directed graph.</p>
<p><em>Perceptrons</em>: Takes a vector of real inputs, calculates a linear comb. If bigger threshold, output 1; 0 otherwise<br>Learning a perceptron = choosing values for the <em>coeffs</em>!<br>It can represent primitive boolean functions AND, OR, NAND, …<br>And all boolean functions in general<br>Training a perceptron: start with arbitrary weights, repeat… (p88)<br>to modify $w_i$ to new $w_i$: $\Delta w_i = \ita (t-o)x_i$, where $\ita$ is the Learning Rate, which is a small value.</p>
<h1 id="Lecture_13">Lecture 13</h1>
<p>Single Linear Unit / Network of L.U.’s / Perceptron(STEP fxn,Classifier) / Network of Perceptrons<br>Expressive Power(hard bias): All Linear fxns / Still Linear, / Linear Classifiers / Any decision problem<br>Optimization Criterion(soft bias): Mean Squared Error / Same / Misclassific Rate / Same<br>Computational complexity: Algebraically, Gradient Decent / Same / Perceptron Learning Rule / Not continuous (No known feasible algo.)</p>
<p>(no bias -&gt; no learning)<br>Sigmoid function:<br>Network of Sigmoid: any function / MSE / Gradient Decent (exists local minimal)</p>
<p><em>Back Propagation</em>:</p>
<h1 id="Midterm_Prep">Midterm Prep</h1>
<p>Data mining: extract information from a large data set and transform it to a structure for future use<br>Target function<br>Hypothesis: h is a <em>conjunction</em> of constraints on attributes<br>constraints: value; don’t care; no value allowed;<br>Concept learning:<br>Training example: &lt;$x_1$, c($x_1$)&gt;, where c is the <em>target function</em> or <em>concept</em>.<br>Determine: h such that h(x) = c(x) for all x in D<br>Find-S: h0 = most specific (no to everything); for each pos example, “merge” the attribute constraint<br>consistent: (h, D) if h(x) = c(x) for all c in D<br>version space: subset of H(hypothesis space) consistent with all training data D<br>List-then-Eliminate: start with the biggest hypothesis space; find version space by checking each training example<br>Input Space: X, Hypothesis Space: H (+1), Concept Space: $2^{|X|}$</p>
<p>Information Theory<br>Information: Reduction in uncertainty: $I(E)=log_2\frac{1}{P(E)}$<br>Entropy: From a Zero-memory source S, the entropy is $\Sigma_i p_i * I(s_i) = E[log\frac{1}{p_i}]$<br>avg amount of information<br>H(T, M) &lt; H(T) + H(M) ???<br>q distribution ???<br>H(T) - H(T|M) = H(M) - H(M|T) ???</p>
<h1 id="Lecture_15">Lecture 15</h1>
<h3 id="Hypothesis_Testing">Hypothesis Testing</h3>
<p>Q1: Given a hypothesis, how good is it?<br>Q2: Given two hypothesis, which one is better?<br>Q3: Given two learning algorithms, which one is better?<br>Not about the portion of the mistakes in the whole input space, but the probability of making errors.(Consider when most of the examples are mistakes)<br>$Err_r(h)$ is an estimator of $Err_D(h)$.<br>$BIAS = E[EST] - TRUTH$ (Mean is around the truth)<br>$VARIANCE = E[EST - E[EST]]^2$(Also needs to be accurate (sharp around the truth))<br>True Error to Sample Error (Probability calculation)<br>Sample Error to True Error (Statistical Inferrence)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2015/01/21/Machine-Learning-Notes/" data-id="vcrxzwcsv358nhfc" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2015/01/21/Machine-Learning-Notes/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/notes/">notes</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post--15251-Deductive-Systems-and-Propositional-Logic" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/15/-15251-Deductive-Systems-and-Propositional-Logic/" class="article-date">
  <time datetime="2015-01-16T02:42:59.000Z" itemprop="datePublished">Jan 15 2015</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/15/-15251-Deductive-Systems-and-Propositional-Logic/">[15251] Deductive Systems and Propositional Logic</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <h3 id="Deductive_System">Deductive System</h3>
<p>A <strong>Deductive</strong> System consists of</p>
<ul>
<li>One or more <strong>initial objects</strong></li>
<li>One or more <strong>deduction rules</strong></li>
</ul>
<h3 id="Propositional_Logic">Propositional Logic</h3>
<p><em>doesn’t</em> have quantifiers, or “First Order Logic”</p>
<ul>
<li><strong>Propositional Variables</strong>: basic statements that can be either true or false, like $p, w, r, x_1, x_2, x_3$</li>
<li><strong>Connectives</strong>:<ul>
<li>Not $\neg$</li>
<li>And $\wedge$</li>
<li>Or $\vee$</li>
<li>Implies $\rightarrow$</li>
<li>If and Only if $\leftrightarrow$</li>
</ul>
</li>
</ul>
<p><strong>formula</strong>: Connectives and P.V.<br><em>well-formed formula</em>:</p>
<ul>
<li>Initial: Any variable</li>
<li>Deduction Rules: From $A$, can obtain $\neg A$. From $A, B$, can obtain $A\vee B$, $A\wedge B$, $A\rightarrow B$, $A\leftrightarrow B$.</li>
</ul>
<p>A formula is a binary tree in which:</p>
<ul>
<li>2-child nodes are labeled by <em>binary ops</em></li>
<li>1-child nodes are labeled by <em>unary ops</em></li>
<li>0-child nodes are labeled by <em>variables</em></li>
</ul>
<p><em>Truth Assignment V</em>: setting of true and false for each variable<br>Given a formula $S$, its truth value $V[S]$ can be defined by <em>structural induction</em></p>
<p><strong>Satisfiability</strong>:</p>
<ul>
<li>$V$ satisfies $S$: $V[S] = T$</li>
<li>$S$ is satisfiable: $\exists V$ such that $V[S] = T$</li>
<li>$S$ is unsatisfiable: $\forall V, V[S] = F$</li>
<li>$S$ is tautology: $\forall V, V[S] = T$</li>
</ul>
<p><em>Equivalent</em>: Formulas $R$ and $S$ are equivalent, $R \equiv S$ if $\forall V, V[R] = V[S]$.<br><em>Entailment</em>: Formulas $A_1, …, A_m$ entail formula $S$, written $A_1, …, A_m \models S$ if every truth assignment which makes $A_i$ true makes $S$ true.<br><em>Truth table</em>: It represents a <em>Boolean function</em>, $f: {0, 1}^n \rightarrow {0, 1}$.</p>
<ul>
<li>There are $2^{2^n}$ truth tables on n variables.</li>
<li>Every truth table can be computed by some formula, only using $\neg, \vee, \wedge$</li>
</ul>
<p><strong>Circuits</strong></p>
<ul>
<li>In circuits, nodes (gates) may have fan-out &gt; 1.</li>
<li>Formulas are trees: all nodes have fan-out 1.</li>
<li>Circuits can reuse already-computed pieces. Formulas cannot; everything must be “rebuilt”.</li>
<li>Deduction viewpoint: The circuit is the deduction. The formula is the last line.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2015/01/15/-15251-Deductive-Systems-and-Propositional-Logic/" data-id="zzwj5bs25obm0219" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2015/01/15/-15251-Deductive-Systems-and-Propositional-Logic/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/251/">251</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/math/">math</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Dark-Meat-vs-White-Meat-Which-meat-to-have-at-KFC" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/13/Dark-Meat-vs-White-Meat-Which-meat-to-have-at-KFC/" class="article-date">
  <time datetime="2015-01-14T01:10:51.000Z" itemprop="datePublished">Jan 13 2015</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/13/Dark-Meat-vs-White-Meat-Which-meat-to-have-at-KFC/">Dark Meat vs. White Meat - Which meat to have at KFC</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <p>I love KFC. Everyone does. Especially in Pittsburgh, where the winter is cold and humid, it’s always good to get some extra calories. However, I noticed that when I order chicken at KFC, they always ask if I want dark meat or white meat. Dark meat is 1/2 dollars cheaper than white. So I always choose dark to save some money. However, I am always wondering does dark mean “bad quality” or something? I googled it and decided to write a blog about this.<br>I referred to <a href="http://www.quora.com/What-are-the-quantifiable-differences-between-dark-meat-and-white-meat-in-chicken-specifically" target="_blank" rel="external">Peter James’ answer on Quora</a>. You can also find a nutrition chart on this page.<br>Basically, <em>legs</em> and <em>thighs</em> are dark meat, and <em>breast</em> is white meat.<br>I highly recommend dark meat over white. KFC made it seem that dark meat is inferior. In fact, although it has a little bit more calories and fat, it is much more tasty than white. Chicken breast is the most flavorless, dry part on a chicken. On the contrary, legs and thighs are tender, juicy, and flavorful. Get salad not KFC if you want to eat healthy. If you go to KFC, I assume that you don’t care much about the extra calories you get from thighs.<br>中文版就是：<br>我们都是中国人，我们知道鸡腿肉比鸡胸肉不知道高到哪里去了，而且还便宜，以后请放心大胆的点dark meat!</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2015/01/13/Dark-Meat-vs-White-Meat-Which-meat-to-have-at-KFC/" data-id="smwpiy29p04l69pc" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2015/01/13/Dark-Meat-vs-White-Meat-Which-meat-to-have-at-KFC/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/food/">food</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Chicken-Curry-in-30-minutes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/12/Chicken-Curry-in-30-minutes/" class="article-date">
  <time datetime="2015-01-12T05:38:50.000Z" itemprop="datePublished">Jan 12 2015</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/12/Chicken-Curry-in-30-minutes/">Chicken Curry in 30 minutes</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <p>I happened to walk in an Indian market on Craig street. I wanted to try something exotic, and bought this curry powder: <img src="https://lh5.googleusercontent.com/-FI0x1GBT1jU/VLNN0TqgCgI/AAAAAAAAArU/h7GOYj2aIho/w425-h567-no/IMG_20150111_232940.jpg" alt="Curry">.<br>Ingredients:</p>
<ul>
<li>Vegetables(potato, onion)</li>
<li>Chicken thigh(Breast is okay but thigh is more moist and flavorful. Use breast if you do not like skin)</li>
<li>Coconut milk(This makes the curry so different than the ones made with water)<br>Steps:</li>
</ul>
<ol>
<li>Pan-sear the thigh. This burns the fat and makes the skin crispy.<br><img src="https://lh5.googleusercontent.com/-Jgp4XvaqFEk/VLMYJZmu1CI/AAAAAAAAAqk/IMOkdDH2G4I/w425-h567-no/IMG_20150111_194029.jpg" alt="Crispy thighs"></li>
<li>Cut thigh and vegetables into cubes. Stir-fry them with curry powder until they smell fragrant and potatoes turn gold.</li>
<li>Add <em>lots of</em> coconut milk. Do not add water. Let it boil.<br><img src="https://lh6.googleusercontent.com/-K5kbOxtAsco/VLMcOrS6oPI/AAAAAAAAAqo/7k1CzuW_OyA/w425-h567-no/IMG_20150111_195808.jpg" alt="The stew"></li>
<li>Serve it with nice rice. I like to sprinkle some somoked paprika on top of it to make it more tasty.</li>
<li>Enjoy!<br><img src="https://lh4.googleusercontent.com/-AD_0nEsyCuA/VLMjNZ8IpSI/AAAAAAAAAq0/h0kV2aUdGug/w756-h567-no/IMG_20150111_202813.jpg" alt="Final Product"></li>
</ol>
<p>I know it is not the authentic way to cook Indian food, but I think it is fast and tasty. You can try this. Try any combination of meat and vegetables. As long as there is the authentic curry powder and coconut milk, it will be thick, spicy, and tasty.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2015/01/12/Chicken-Curry-in-30-minutes/" data-id="dngtwrsaqpwx391u" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2015/01/12/Chicken-Curry-in-30-minutes/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/food/">food</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Tech-Interview-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/11/15/Tech-Interview-1/" class="article-date">
  <time datetime="2014-11-15T20:27:33.000Z" itemprop="datePublished">Nov 15 2014</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/11/15/Tech-Interview-1/">Tech Interview</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <p>Some topics from either oj.leetcode.com or hackerrank:</p>
<h3 id="Palindrome">Palindrome</h3>
<ul>
<li><a href="https://oj.leetcode.com/problems/palindrome-number/" target="_blank" rel="external">Palindrome Number</a><br>Is a number palindrome?<br>Solution: reverse the integer and see if they equal. Pay attention to the sign<br>Big-O: 0 space n time (n is the length of number)</li>
<li><a href="https://oj.leetcode.com/problems/palindrome-partitioning/" target="_blank" rel="external">Palindrome Partition I</a><br>Find all possible ways to partition a string into palindrome substrings<br>Solution: DP<br>Big-O: n^2 space 2^n time (n is the length of string)</li>
<li><a href="https://oj.leetcode.com/problems/palindrome-partitioning-ii/" target="_blank" rel="external">Palindrome Partition II</a><br>Find the minimum number of cuts to partition a string into palindrome substrings<br>Solution: Double DP. If use the previous problem, too much space and time.<br>Find P[i][j] s.t. P[i][j] is true if s[i:j] is palindrome. D[i] is the mincut<br>of s[i:].<br>Big-O: n^2 space n^2 time (n is the length of string)</li>
<li><a href="https://www.hackerrank.com/challenges/palindrome-index" target="_blank" rel="external">Palindrome Index</a><br>Find the index in the string which if removed, makes the string palindrome<br>Solution: TODO</li>
<li><a href="https://oj.leetcode.com/problems/longest-palindromic-substring/" target="_blank" rel="external">Longest Palindrome Substring</a><br>Solution: We can use the DP in “Pal Part II”, which will have O(n^2) big-O. Or we can use <strong>manacher’s algorithm</strong> in O(n).</li>
</ul>
<hr>
<h3 id="Binary_Tree">Binary Tree</h3>
<ul>
<li><a href="https://oj.leetcode.com/problems/binary-tree-preorder-traversal/" target="_blank" rel="external">Preorder Traversal</a><br>Solution: Trivial</li>
<li><a href="https://oj.leetcode.com/problems/binary-tree-postorder-traversal/" target="_blank" rel="external">Postorder Traversal</a><br>Solution: Trivial</li>
<li><a href="https://oj.leetcode.com/problems/binary-tree-inorder-traversal/" target="_blank" rel="external">Inorder Traversal</a><br>Solution: Trivial</li>
<li><a href="https://oj.leetcode.com/problems/binary-tree-maximum-path-sum/" target="_blank" rel="external">Binary Tree Maximum Sum</a><br>Solution: This problem has a lot of edge cases, and the “path” is not so well-defined in the problem.<br>This problem seems to be a DP problem at the first sight, but if you think about it, you can expand in<br>two directions at the root, but not at children of root, which is not a “path”. I used a hash table<br>to store each node’s single path sum, defined as the max sum reached by going either to the left<br>or to the right, but not both. And traverse the tree to compute each node’s maxPathSum.<br>Big-O: n space nlogn time</li>
<li><a href="https://oj.leetcode.com/problems/flatten-binary-tree-to-linked-list/" target="_blank" rel="external">Flatten Binary Tree to Linked List</a><br>Solution: Use a queue. Brute force solution.<br>Big-O: n space n time</li>
<li><a href="https://oj.leetcode.com/problems/minimum-depth-of-binary-tree/" target="_blank" rel="external">Minimum depth of tree</a><br>Find the minimum distance from root to a leaf node<br>Solution: this problem is not complicated, but not as trivial as it first appears. Consider (1, #, 2) as<br>an edge case.<br>Big-O: 1 space d work</li>
<li><a href="https://oj.leetcode.com/problems/balanced-binary-tree/" target="_blank" rel="external">Balanced Binary Tree</a><br>Solution: Trivial<blockquote>
<p>TODO: AVL Tree</p>
</blockquote>
</li>
<li><a href="https://oj.leetcode.com/problems/convert-sorted-array-to-binary-search-tree/" target="_blank" rel="external">Sorted Array to Binary Tree</a><br>Solution: similar to binary search<br>Big-O: n space n time</li>
<li><a href="https://oj.leetcode.com/problems/convert-sorted-list-to-binary-search-tree/" target="_blank" rel="external">Sorted list to Binary Tree</a><br>Solution: Use the above program<br>Big-O: n space n time</li>
<li><a href="https://oj.leetcode.com/problems/maximum-depth-of-binary-tree/" target="_blank" rel="external">Maximum Depth of Binary Tree </a><br>Solution: Trivial</li>
<li><a href="https://oj.leetcode.com/problems/binary-tree-level-order-traversal/" target="_blank" rel="external">Level order Traversal</a><br>Solution: Create a hash table of <node, height=""><br>Big-O: n time n space</node,></li>
<li><a href="https://oj.leetcode.com/problems/binary-tree-level-order-traversal-ii/" target="_blank" rel="external">Level order Traversal II</a><br>Solution: Similar to the above problem.</li>
<li><a href="https://oj.leetcode.com/problems/binary-tree-zigzag-level-order-traversal/" target="_blank" rel="external">Zigzag level order traversal</a><br>Solution: Similar to the above</li>
<li><a href="https://oj.leetcode.com/problems/same-tree/" target="_blank" rel="external">Same Tree</a><br>Solution: Trivial</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2014/11/15/Tech-Interview-1/" data-id="nvg1p85unjbxi07k" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2014/11/15/Tech-Interview-1/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/">C++</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Interview/">Interview</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CacheLab-Part-B" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/10/07/CacheLab-Part-B/" class="article-date">
  <time datetime="2014-10-07T04:51:02.000Z" itemprop="datePublished">Oct 7 2014</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/10/07/CacheLab-Part-B/">CacheLab Part B</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <h3 id="CacheLab_Part_B">CacheLab Part B</h3>
<blockquote>
<p>Part B of CacheLab is very challenging. I spent tons of hours on this, and I would like to write a blog on how I approached this problem.</p>
</blockquote>
<p>So before going into the details for each problem, there are something we should not that apply to all three problems:</p>
<ul>
<li>The cache has parameters: s = 5, E = 1, b = 5. The b=5 tells us that each line stores 2^5 = 32 bytes, or 8 integers. The E = 1 tells us that it is direct-mapped. And this has a very important implication is that, if we reference two addresses of the same <em>set</em>, the latter will cause the first to evict! This is because we have only one line in one set.</li>
<li>To see why this is important to this lab, let’s run <code>csim</code> against our program and store the trace into a file. We can see that the first matrix starts with <strong>6022e0</strong>, the second starts with <strong>6422e0</strong>. This means that, <em>for the same row of A and B, they are cached to the same set, and will cause conflict.</em></li>
<li>So this means we have to take special care for diagonal entries when transposing the matrix.</li>
<li>Another thing to notice, I borrowed this image from another blog:<br><img src="http://winnieliu.org/images/others/cache32.png" alt="set number for 32*32" title="Access pattern"><br>So when we read A[0][0], we can read A[0][1] to A[0][7] <em>without a single miss</em>. So we want to explore that to avoid misses as much as possible.<h4 id="32_*_32">32 * 32</h4>
Upperbound for misses: 300<br>Please refer to the image for 32 <em> 32. In this case, if we deal with 8</em>8 blocks, then we can avoid misses because we can store each row in a cache line, which is of <strong>8</strong> integers. However, we should avoid accessing diagonal entries in the loop. This is because if we do this:</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">B[<span class="link_label">i</span>][<span class="link_reference">j</span>] = A[<span class="link_label">j</span>][<span class="link_reference">i</span>]</div></pre></td></tr></table></figure>

<p>Since for diagonal entries, i=j, we kiced A[j] out of the cache with B[i]. So we will check for diagonal entry in each loop, store it in a temporary variable, and put it in B after the loop.<br>This approach makes <strong>287</strong> misses.</p>
<h4 id="61_*_67">61 * 67</h4>
<p>Upperbound for misses 2000<br>We can use the same approach of blocking to divide this matrix to sub-matrices. This problem is trivial compared to <strong>64*64</strong>. I found that if we try different sizes of sub-matrices, we can get some pretty good results. My best <strong>guess</strong> so far is 18, with <strong>1815</strong> misses.</p>
<h4 id="64_*_64">64 * 64</h4>
<p>This is the most interesting/challenging problem. If we try to simply divide the matrix into smaller matrices, we get somewhere between 1600 ~ 2000 depending on the size of the sub matrix. We will first look at the graph, again, credit to winnieliu, who had an amazing <a href="https://winnieliu.org" target="_blank" rel="external">blog</a>.<br><img src="http://winnieliu.org/images/others/cache64.png" alt="set number for 64 * 64"><br>We can see that since our cache can only store 32 <em> 32 bytes, which is 32 </em> 8 integers, it doesn’t make much sense in this case to do 8<em>8 blocks because we will have misses in 8</em>8 blocks. 0 will conflict with 0, 1 with 1, etc. It seems like 4 <em> 8 is a pretty good candidate, but 4 </em> 8 is not a square and can thus make things complicated.</p>
<h5 id="First_Try">First Try</h5>
<p>I tried to use 4*4 blocks first. I tried to use 8 local variables, which is the max number of local vars I can manage to use. It gives 1630-ish misses. Not good enough. So I ran <code>csim</code> against this solution, and looked for the misses. I found that since we only have 8 vars, if we access 2 rows of length 4 of A, we have good locality on A, because we have 2 misses for 8 references. However, we have very bad locality for B, because in B, this is 4 rows of 2 cols, we have 4 misses in 8 references.<br>If we try to figure out why this doesn’t work, we can tell that:</p>
<ul>
<li>We didn’t fully explore the fact that once we load A[0][0], <strong>eight</strong> numbers are loaded. We just used <strong>four</strong>.</li>
<li>We didn’t have a good <strong>access pattern</strong> for B. We are jumping back and forth.</li>
</ul>
<p>So we kind of have this idea that, we still want the width of the sub matrix to be 8 to use that at our advantage.<br>So we still divide it into 8*8 blocks. But this time, instead of solving it row by row, we are going to divide it even more to 4 4 by 4 blocks. So suppose <code>i, j</code> are the coordinates for the top-left corner of this 8 by 8 block. We use a iterator <code>k</code> to help use traverse inside this block. We can label it as:<br>| a  |  b |<br>| c  |  d |<br>where a, b, c, d are 4 by 4.</p>
<h5 id="a">a</h5>
<p>So to fill a, we need to access row j ~ j+3, col i~i+3 of A (so that rows of B can be i~i+3, cols of B can be j ~ j+3). However, instead of reading four cols, we know we can read <strong>8</strong> cols without misses. So we read col i~i+7 of A, for i~i+3, we do the usual transpose, for i+4 ~ i+5, instead of transposing them, which will cause more misses to the next step, we are going to store them in the position of b.<br>An example of doing so is:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tmp = A[<span class="link_label">k</span>][<span class="link_reference">i+4</span>];</div><div class="line">B[<span class="link_label">i</span>][<span class="link_reference">k+4</span>] = tmp;</div></pre></td></tr></table></figure>

<p>So an interesting to note after we have transposed a, c’s transpose is now in b.</p>
<h5 id="b_c">b c</h5>
<p>We are going to do b and c together.<br>So we scan a row of b to local variables, find values in A to fill the row in b, and use local variables to fill a row of c. Repeat this step four times.</p>
<h5 id="d">d</h5>
<p>Nothing special here, for (i, j) in B, just look for (j, i) in A. Fill d row by row to use cache at our advantage.<br>This algorithm gives us a total misses of <strong>1219</strong>.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2014/10/07/CacheLab-Part-B/" data-id="1vz4kgylwliy7unh" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2014/10/07/CacheLab-Part-B/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cachelab/">cachelab</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Create-a-blog-with-hexo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/10/05/Create-a-blog-with-hexo/" class="article-date">
  <time datetime="2014-10-06T02:13:18.000Z" itemprop="datePublished">Oct 5 2014</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/10/05/Create-a-blog-with-hexo/">Create a blog with hexo</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody" style="display:none">
      
        <p>I started to get bored with writing a blog on wordpress.com. It should be more exciting to host my own blog. So I googled and found this blog framework <em>Hexo</em>. It’s super easy to use for someone with a basic understanding of nodejs applications and simple deployment on Github/Heroku etc. Anyway, it’s a fun thing to do! Hopefully I can keep writing more blogs.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://pavelkang.github.io/2014/10/05/Create-a-blog-with-hexo/" data-id="6fyzg5gg95syf8xs" class="article-share-link">Share</a>
      
        <a href="https://pavelkang.github.io/2014/10/05/Create-a-blog-with-hexo/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hexo/">hexo</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/251/">251</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Interview/">Interview</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cachelab/">cachelab</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/emacs/">emacs</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/food/">food</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/math/">math</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/notes/">notes</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/schedule/">schedule</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/213/" style="font-size: 10.00px;">213</a><a href="/tags/251/" style="font-size: 20.00px;">251</a><a href="/tags/C/" style="font-size: 12.50px;">C++</a><a href="/tags/Interview/" style="font-size: 12.50px;">Interview</a><a href="/tags/Python/" style="font-size: 12.50px;">Python</a><a href="/tags/algorithm/" style="font-size: 10.00px;">algorithm</a><a href="/tags/cachelab/" style="font-size: 12.50px;">cachelab</a><a href="/tags/cachelab-213/" style="font-size: 10.00px;">cachelab 213</a><a href="/tags/cachelab-213/" style="font-size: 10.00px;">cachelab, 213</a><a href="/tags/cachelab-213/" style="font-size: 10.00px;">cachelab; 213</a><a href="/tags/combination/" style="font-size: 10.00px;">combination</a><a href="/tags/editor/" style="font-size: 10.00px;">editor</a><a href="/tags/emacs/" style="font-size: 15.00px;">emacs</a><a href="/tags/food/" style="font-size: 17.50px;">food</a><a href="/tags/hexo/" style="font-size: 12.50px;">hexo</a><a href="/tags/leetcode/" style="font-size: 10.00px;">leetcode</a><a href="/tags/lisp/" style="font-size: 10.00px;">lisp</a><a href="/tags/machine-learning/" style="font-size: 12.50px;">machine learning</a><a href="/tags/math/" style="font-size: 20.00px;">math</a><a href="/tags/notes/" style="font-size: 12.50px;">notes</a><a href="/tags/permutation/" style="font-size: 10.00px;">permutation</a><a href="/tags/schedule/" style="font-size: 12.50px;">schedule</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">April 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">March 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">February 2015</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">January 2015</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">November 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">October 2014</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/05/14/Learning-Emacs-Lisp/">Learning Emacs Lisp</a>
          </li>
        
          <li>
            <a href="/2015/05/10/Making-Emacs-a-Better-C-C-IDE/">Making Emacs a Better C/C++ IDE</a>
          </li>
        
          <li>
            <a href="/2015/05/06/251-Final-Review/">251 Final Review</a>
          </li>
        
          <li>
            <a href="/2015/04/06/最近想做的菜/">最近想做的菜</a>
          </li>
        
          <li>
            <a href="/2015/03/31/15251-randomness/">15251-randomness</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 Kai Kang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/resume" class="mobile-nav-link">Resume</a>
  
    <a href="http://www.kaikang.me" class="mobile-nav-link">Visit My Home Page</a>
  
</nav>
    
<script>
  var disqus_shortname = 'sclingtt';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">

  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>



<script src="/js/script.js" type="text/javascript"></script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </div>
</body>
</html>